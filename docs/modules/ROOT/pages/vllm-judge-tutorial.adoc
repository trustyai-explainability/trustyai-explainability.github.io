= vLLM Judge

A lightweight library for LLM-as-a-Judge evaluations using vLLM hosted (or any OpenAI API-compatible) models. Evaluate LLM inputs & outputs at scale with just a few lines of code. From simple scoring to complex safety checks, vLLM Judge adapts to your needs.

== Features

* ğŸš€ **Simple Interface**: Single `evaluate()` method that adapts to any use case
* ğŸ”§ **Template Support**: Dynamic evaluations with template variables
* ğŸ¯ **Pre-built Metrics**: 20+ ready-to-use evaluation metrics
* ğŸ’¬ **Conversation Support**: Evaluate entire conversations with multi-turn dialog
* ğŸ›¡ï¸ **Model-Specific Support**: Seamlessly works with specialized models like Llama Guard 3 & Granite Guardian 3.2 without breaking their trained formats
* âš¡ **High Performance**: Async-first design enables high-throughput evaluations
* ğŸŒ **API Mode**: Run as a REST API service

[NOTE]
====
ğŸ“¦ **Source Code**: https://github.com/trustyai-explainability/vllm_judge[GitHub Repository] | ğŸ› **Issues**: https://github.com/trustyai-explainability/vllm_judge/issues[Report Bugs] | ğŸ“– **PyPI**: https://pypi.org/project/vllm-judge/[Package]
====


== Getting Started

=== Installation

Basic installation with pip:

[source,bash]
----
pip install vllm-judge
----

For detailed installation instructions, prerequisites, and environment setup, see xref:vllm-judge-installation.adoc[Installation Guide].

=== Your First Evaluation

[source,python]
----
from vllm_judge import Judge

# Initialize with vLLM server URL
judge = Judge.from_url("http://vllm-server:8000")

# Simple evaluation
result = await judge.evaluate(
    content="The Earth orbits around the Sun.",
    criteria="scientific accuracy"
)
print(f"Decision: {result.decision}")
print(f"Reasoning: {result.reasoning}")
----

== What's Next?

=== ğŸ“š Learn the Basics
* **xref:vllm-judge-installation.adoc[Installation Guide]** - Detailed setup instructions and prerequisites
* **xref:vllm-judge-quickstart.adoc[Quick Start Guide]** - Get up and running with comprehensive examples in 5 minutes

=== ğŸ”§ Advanced Usage
* **xref:vllm-judge-basic-evaluation.adoc[Basic Evaluation Guide]** - Deep dive into evaluation options and patterns
* **xref:vllm-judge-metrics.adoc[Using Metrics]** - Explore all 20+ pre-built metrics
* **xref:vllm-judge-templates.adoc[Template Variables]** - Advanced templating features for dynamic evaluations

Ready to get started? Head to the xref:vllm-judge-installation.adoc[Installation Guide] or jump straight into the xref:vllm-judge-quickstart.adoc[Quick Start Guide]!